import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

class DirectoryScanner:
    def __init__(self, base_url):
        self.base_url = base_url

    def scan(self):
        try:
          
            response = requests.get(self.base_url)
            
            
            if response.status_code == 200:
                print(f"Scanning directory: {self.base_url}")
                
               
                soup = BeautifulSoup(response.text, 'html.parser')
                
              
                links = soup.find_all('a')
                
               
                for link in links:
                    href = link.get('href')
                    full_url = urljoin(self.base_url, href)
                    print(full_url)
            else:
                print(f"Failed to access {self.base_url}, status code: {response.status_code}")
        except requests.exceptions.RequestException as e:
            print(f"Error: {e}")


if __name__ == "__main__":
    url = input("Masukkan URL direktori yang ingin discan: ")
    scanner = DirectoryScanner(url)
    scanner.scan()
